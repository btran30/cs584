{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY5c1IBb4OVS"
   },
   "source": [
    "# ResNet50 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24x8j0HORkj2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.datasets import cifar100, cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(num_classes):\n",
    "\n",
    "    if num_classes == 100:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "    else :\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        \n",
    "    x_train = preprocess_input(x_train)\n",
    "    x_test = preprocess_input(x_test)\n",
    "   \n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "       \n",
    "    print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "    print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "    return (x_train, y_train), (x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(num_classes, x_train, y_train, x_test, y_test):\n",
    "    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in resnet_model.layers:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(UpSampling2D(size=(7,7)))\n",
    "    model.add(resnet_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(rotation_range=8,\n",
    "                             shear_range=0.2, \n",
    "                             zoom_range=0.2,\n",
    "                             channel_shift_range=0.05, \n",
    "                             horizontal_flip=True)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    t=time.time()\n",
    "    nb_epochs = 10\n",
    "    batch_size = 64\n",
    "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                  steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                                  epochs=nb_epochs,\n",
    "                                  validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (t - time.time()))\n",
    "    model.save('ResNet50_cifar'+str(cifar_class)+'.h5')\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(num_classes, history):\n",
    "    cifar = 'CIFAR'+str(num_classes)\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title(cifar + ' Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title(cifar + ' Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    #filename = \"ResNet50_Pretrained\"\n",
    "    #plt.savefig(filename + '_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x_test, y_test):\n",
    "    ypred = model.predict(x_test)\n",
    "\n",
    "    total = 0\n",
    "    accurate = 0\n",
    "    accurateindex = []\n",
    "    wrongindex = []\n",
    "\n",
    "    for i in range(len(ypred)):\n",
    "        if np.argmax(ypred[i]) == np.argmax(y_test[i]):\n",
    "            accurate += 1\n",
    "            accurateindex.append(i)\n",
    "        else:\n",
    "            wrongindex.append(i)\n",
    "\n",
    "        total += 1\n",
    "    \n",
    "    print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
    "    print('Accuracy:', round(accurate/total*100, 3), '%')\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxFpNfWWcunj",
    "outputId": "9dbf881a-7bed-4a03-efa4-a992fb784c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_6 (UpSampling2 (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 24,138,980\n",
      "Trainable params: 603,876\n",
      "Non-trainable params: 23,535,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "(x_train, y_train), (x_test, y_test) = pre_process_data(num_classes)\n",
    "history, model = fit_model(num_classes, x_train, y_train,x_test, y_test)\n",
    "print('\\n\\n')\n",
    "summarize_diagnostics(num_classes, history)\n",
    "print('\\n')\n",
    "predict(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = preprocess_data(num_classes)\n",
    "history, model = fit_model(num_classes, x_train, y_train,x_test, y_test)\n",
    "print('\\n\\n')\n",
    "summarize_diagnostics(num_classes, history)\n",
    "print('\\n')\n",
    "predict(model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ResNet50_pretrained.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
