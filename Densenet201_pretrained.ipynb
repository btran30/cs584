{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Densenet201_pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btran30/cs584/blob/brenda/Densenet201_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY5c1IBb4OVS"
      },
      "source": [
        "# DenseNet 201 Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoamKGa4XSl"
      },
      "source": [
        "## Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjZlTdjjfXLr",
        "outputId": "340957b5-e600-4cb8-894a-d81bcc2134c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization,Activation\n",
        "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Tensorflow-version:\", tensorflow.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow-version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8rl-qhF4lP-"
      },
      "source": [
        "## Load Data from Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ0MfUxMfXL5",
        "outputId": "acbe651d-87d1-4b2c-93af-cdc4b49069bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.cifar100.load_data()\n",
        "\n",
        "# One-hot encoding for 100 classes.\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train: X=(50000, 32, 32, 3), y=(50000, 100)\n",
            "Test: X=(10000, 32, 32, 3), y=(10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjw4aw-b4qEs"
      },
      "source": [
        "## DenseNet 201 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW5ANnlB4xC_"
      },
      "source": [
        "We utilize ImageDataGenerator to augment our input data.  This should help us avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJXdLY1zXqwF",
        "outputId": "5446defc-5a8f-4712-c0e9-6d52a5185ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_shape=(32,32,3)\n",
        "model_d=DenseNet201(weights='imagenet',include_top=False, input_shape=input_shape) \n",
        "\n",
        "x=model_d.output\n",
        "\n",
        "x= BatchNormalization()(x)\n",
        "x= Activation('relu')(x)\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "\n",
        "preds=Dense(100,activation='softmax')(x) #FC-layer\n",
        "\n",
        "model=Model(inputs=model_d.input, outputs=preds)\n",
        "\n",
        "#model.summary()\n",
        "#tf.keras.utils.plot_model( model , show_shapes=True )\n",
        "\n",
        "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
        "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "# Fits-the-model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "               steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "               epochs=epochs,\n",
        "               verbose=1,\n",
        "               callbacks=[anne, checkpoint],\n",
        "               validation_data=(x_test, y_test))\n",
        "\n",
        "#model.save(\"m_densenet201.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 3.4858 - accuracy: 0.2258 - top_k_categorical_accuracy: 0.4444\n",
            "Epoch 00001: val_loss improved from inf to 2.63600, saving model to model.h5\n",
            "390/390 [==============================] - 54s 138ms/step - loss: 3.4858 - accuracy: 0.2258 - top_k_categorical_accuracy: 0.4444 - val_loss: 2.6360 - val_accuracy: 0.3677 - val_top_k_categorical_accuracy: 0.6815\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 2.1777 - accuracy: 0.4432 - top_k_categorical_accuracy: 0.7492\n",
            "Epoch 00002: val_loss improved from 2.63600 to 2.06248, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 2.1777 - accuracy: 0.4432 - top_k_categorical_accuracy: 0.7492 - val_loss: 2.0625 - val_accuracy: 0.4641 - val_top_k_categorical_accuracy: 0.7664\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.7378 - accuracy: 0.5348 - top_k_categorical_accuracy: 0.8257\n",
            "Epoch 00003: val_loss improved from 2.06248 to 1.88190, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.7378 - accuracy: 0.5348 - top_k_categorical_accuracy: 0.8257 - val_loss: 1.8819 - val_accuracy: 0.4931 - val_top_k_categorical_accuracy: 0.7937\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.4867 - accuracy: 0.5919 - top_k_categorical_accuracy: 0.8669\n",
            "Epoch 00004: val_loss improved from 1.88190 to 1.63573, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.4867 - accuracy: 0.5919 - top_k_categorical_accuracy: 0.8669 - val_loss: 1.6357 - val_accuracy: 0.5503 - val_top_k_categorical_accuracy: 0.8384\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.3119 - accuracy: 0.6348 - top_k_categorical_accuracy: 0.8916\n",
            "Epoch 00005: val_loss improved from 1.63573 to 1.59250, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.3119 - accuracy: 0.6348 - top_k_categorical_accuracy: 0.8916 - val_loss: 1.5925 - val_accuracy: 0.5608 - val_top_k_categorical_accuracy: 0.8441\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.1701 - accuracy: 0.6721 - top_k_categorical_accuracy: 0.9126\n",
            "Epoch 00006: val_loss improved from 1.59250 to 1.48924, saving model to model.h5\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.1701 - accuracy: 0.6721 - top_k_categorical_accuracy: 0.9126 - val_loss: 1.4892 - val_accuracy: 0.5869 - val_top_k_categorical_accuracy: 0.8617\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.7069 - top_k_categorical_accuracy: 0.9284\n",
            "Epoch 00007: val_loss improved from 1.48924 to 1.41007, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.0411 - accuracy: 0.7069 - top_k_categorical_accuracy: 0.9284 - val_loss: 1.4101 - val_accuracy: 0.6065 - val_top_k_categorical_accuracy: 0.8739\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.9392 - accuracy: 0.7328 - top_k_categorical_accuracy: 0.9397\n",
            "Epoch 00008: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.9392 - accuracy: 0.7328 - top_k_categorical_accuracy: 0.9397 - val_loss: 1.4384 - val_accuracy: 0.6001 - val_top_k_categorical_accuracy: 0.8729\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.7652 - top_k_categorical_accuracy: 0.9542\n",
            "Epoch 00009: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.8303 - accuracy: 0.7652 - top_k_categorical_accuracy: 0.9542 - val_loss: 1.5092 - val_accuracy: 0.5925 - val_top_k_categorical_accuracy: 0.8606\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.7479 - accuracy: 0.7893 - top_k_categorical_accuracy: 0.9618\n",
            "Epoch 00010: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.7479 - accuracy: 0.7893 - top_k_categorical_accuracy: 0.9618 - val_loss: 1.4183 - val_accuracy: 0.6152 - val_top_k_categorical_accuracy: 0.8745\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.8099 - top_k_categorical_accuracy: 0.9693\n",
            "Epoch 00011: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.6726 - accuracy: 0.8099 - top_k_categorical_accuracy: 0.9693 - val_loss: 1.4567 - val_accuracy: 0.6069 - val_top_k_categorical_accuracy: 0.8681\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.8329 - top_k_categorical_accuracy: 0.9760\n",
            "Epoch 00012: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.5991 - accuracy: 0.8329 - top_k_categorical_accuracy: 0.9760 - val_loss: 1.4633 - val_accuracy: 0.6110 - val_top_k_categorical_accuracy: 0.8680\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8548 - top_k_categorical_accuracy: 0.9818\n",
            "Epoch 00013: val_loss did not improve from 1.41007\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.5248 - accuracy: 0.8548 - top_k_categorical_accuracy: 0.9818 - val_loss: 1.4273 - val_accuracy: 0.6199 - val_top_k_categorical_accuracy: 0.8774\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8701 - top_k_categorical_accuracy: 0.9862\n",
            "Epoch 00014: val_loss improved from 1.41007 to 1.39592, saving model to model.h5\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 0.4725 - accuracy: 0.8701 - top_k_categorical_accuracy: 0.9862 - val_loss: 1.3959 - val_accuracy: 0.6302 - val_top_k_categorical_accuracy: 0.8801\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8872 - top_k_categorical_accuracy: 0.9892\n",
            "Epoch 00015: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.4191 - accuracy: 0.8872 - top_k_categorical_accuracy: 0.9892 - val_loss: 1.4223 - val_accuracy: 0.6257 - val_top_k_categorical_accuracy: 0.8779\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9013 - top_k_categorical_accuracy: 0.9913\n",
            "Epoch 00016: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.3710 - accuracy: 0.9013 - top_k_categorical_accuracy: 0.9913 - val_loss: 1.4447 - val_accuracy: 0.6259 - val_top_k_categorical_accuracy: 0.8762\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.9127 - top_k_categorical_accuracy: 0.9937\n",
            "Epoch 00017: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 0.3332 - accuracy: 0.9127 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.4137 - val_accuracy: 0.6328 - val_top_k_categorical_accuracy: 0.8824\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.9262 - top_k_categorical_accuracy: 0.9954\n",
            "Epoch 00018: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.2876 - accuracy: 0.9262 - top_k_categorical_accuracy: 0.9954 - val_loss: 1.4388 - val_accuracy: 0.6327 - val_top_k_categorical_accuracy: 0.8831\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9360 - top_k_categorical_accuracy: 0.9961\n",
            "Epoch 00019: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.2582 - accuracy: 0.9360 - top_k_categorical_accuracy: 0.9961 - val_loss: 1.4103 - val_accuracy: 0.6386 - val_top_k_categorical_accuracy: 0.8827\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9968\n",
            "Epoch 00020: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.2421 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9968 - val_loss: 1.4275 - val_accuracy: 0.6409 - val_top_k_categorical_accuracy: 0.8861\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9494 - top_k_categorical_accuracy: 0.9975\n",
            "Epoch 00021: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.2105 - accuracy: 0.9494 - top_k_categorical_accuracy: 0.9975 - val_loss: 1.4758 - val_accuracy: 0.6303 - val_top_k_categorical_accuracy: 0.8770\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9552 - top_k_categorical_accuracy: 0.9985\n",
            "Epoch 00022: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.1889 - accuracy: 0.9552 - top_k_categorical_accuracy: 0.9985 - val_loss: 1.4607 - val_accuracy: 0.6376 - val_top_k_categorical_accuracy: 0.8809\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9623 - top_k_categorical_accuracy: 0.9986\n",
            "Epoch 00023: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.1657 - accuracy: 0.9623 - top_k_categorical_accuracy: 0.9986 - val_loss: 1.4892 - val_accuracy: 0.6352 - val_top_k_categorical_accuracy: 0.8781\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9627 - top_k_categorical_accuracy: 0.9988\n",
            "Epoch 00024: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.1585 - accuracy: 0.9627 - top_k_categorical_accuracy: 0.9988 - val_loss: 1.4693 - val_accuracy: 0.6421 - val_top_k_categorical_accuracy: 0.8816\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9681 - top_k_categorical_accuracy: 0.9991\n",
            "Epoch 00025: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.1424 - accuracy: 0.9681 - top_k_categorical_accuracy: 0.9991 - val_loss: 1.4806 - val_accuracy: 0.6409 - val_top_k_categorical_accuracy: 0.8813\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9716 - top_k_categorical_accuracy: 0.9991\n",
            "Epoch 00026: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.1289 - accuracy: 0.9716 - top_k_categorical_accuracy: 0.9991 - val_loss: 1.4770 - val_accuracy: 0.6421 - val_top_k_categorical_accuracy: 0.8864\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9742 - top_k_categorical_accuracy: 0.9993\n",
            "Epoch 00027: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 119ms/step - loss: 0.1175 - accuracy: 0.9742 - top_k_categorical_accuracy: 0.9993 - val_loss: 1.5370 - val_accuracy: 0.6330 - val_top_k_categorical_accuracy: 0.8789\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9768 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 00028: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.1078 - accuracy: 0.9768 - top_k_categorical_accuracy: 0.9995 - val_loss: 1.4865 - val_accuracy: 0.6450 - val_top_k_categorical_accuracy: 0.8843\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9783 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 00029: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.1017 - accuracy: 0.9783 - top_k_categorical_accuracy: 0.9995 - val_loss: 1.5498 - val_accuracy: 0.6323 - val_top_k_categorical_accuracy: 0.8807\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9803 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 00030: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.0955 - accuracy: 0.9803 - top_k_categorical_accuracy: 0.9996 - val_loss: 1.5730 - val_accuracy: 0.6331 - val_top_k_categorical_accuracy: 0.8738\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9813 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 00031: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.0885 - accuracy: 0.9813 - top_k_categorical_accuracy: 0.9996 - val_loss: 1.5271 - val_accuracy: 0.6448 - val_top_k_categorical_accuracy: 0.8806\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9825 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00032: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.0822 - accuracy: 0.9825 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5054 - val_accuracy: 0.6519 - val_top_k_categorical_accuracy: 0.8866\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9841 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00033: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0768 - accuracy: 0.9841 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.6016 - val_accuracy: 0.6351 - val_top_k_categorical_accuracy: 0.8742\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9856 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00034: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0728 - accuracy: 0.9856 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5360 - val_accuracy: 0.6452 - val_top_k_categorical_accuracy: 0.8838\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9857 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00035: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0700 - accuracy: 0.9857 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5461 - val_accuracy: 0.6430 - val_top_k_categorical_accuracy: 0.8825\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9854 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00036: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0677 - accuracy: 0.9854 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5405 - val_accuracy: 0.6470 - val_top_k_categorical_accuracy: 0.8808\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9873 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0621 - accuracy: 0.9873 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5319 - val_accuracy: 0.6497 - val_top_k_categorical_accuracy: 0.8823\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9878 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00038: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 120ms/step - loss: 0.0607 - accuracy: 0.9878 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5526 - val_accuracy: 0.6451 - val_top_k_categorical_accuracy: 0.8832\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9884 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00039: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 124ms/step - loss: 0.0569 - accuracy: 0.9884 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.5567 - val_accuracy: 0.6515 - val_top_k_categorical_accuracy: 0.8803\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9892 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00040: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0545 - accuracy: 0.9892 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.5945 - val_accuracy: 0.6425 - val_top_k_categorical_accuracy: 0.8785\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9895 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 00041: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0521 - accuracy: 0.9895 - top_k_categorical_accuracy: 0.9997 - val_loss: 1.5885 - val_accuracy: 0.6472 - val_top_k_categorical_accuracy: 0.8820\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9899 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0510 - accuracy: 0.9899 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6030 - val_accuracy: 0.6423 - val_top_k_categorical_accuracy: 0.8776\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9905 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00043: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0472 - accuracy: 0.9905 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.5809 - val_accuracy: 0.6492 - val_top_k_categorical_accuracy: 0.8787\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9900 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00044: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0470 - accuracy: 0.9900 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.5874 - val_accuracy: 0.6461 - val_top_k_categorical_accuracy: 0.8821\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9898 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00045: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 0.0463 - accuracy: 0.9898 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.5959 - val_accuracy: 0.6465 - val_top_k_categorical_accuracy: 0.8803\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9926 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 00046: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0398 - accuracy: 0.9926 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.6510 - val_top_k_categorical_accuracy: 0.8826\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9919 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0396 - accuracy: 0.9919 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6301 - val_accuracy: 0.6389 - val_top_k_categorical_accuracy: 0.8769\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9927 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00048: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0369 - accuracy: 0.9927 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6019 - val_accuracy: 0.6465 - val_top_k_categorical_accuracy: 0.8803\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9925 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 00049: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.0360 - accuracy: 0.9925 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6068 - val_accuracy: 0.6451 - val_top_k_categorical_accuracy: 0.8812\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9930 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00050: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0366 - accuracy: 0.9930 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.6411 - val_accuracy: 0.6446 - val_top_k_categorical_accuracy: 0.8782\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9925 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00051: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 0.0365 - accuracy: 0.9925 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.6562 - val_accuracy: 0.6439 - val_top_k_categorical_accuracy: 0.8782\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9944 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0319 - accuracy: 0.9944 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6330 - val_accuracy: 0.6470 - val_top_k_categorical_accuracy: 0.8799\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9940 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00053: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 0.0319 - accuracy: 0.9940 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.7707 - val_accuracy: 0.6224 - val_top_k_categorical_accuracy: 0.8631\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9928 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00054: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 0.0355 - accuracy: 0.9928 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6579 - val_accuracy: 0.6447 - val_top_k_categorical_accuracy: 0.8762\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9909 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 00055: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0428 - accuracy: 0.9909 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.6312 - val_accuracy: 0.6496 - val_top_k_categorical_accuracy: 0.8780\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9927 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00056: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0358 - accuracy: 0.9927 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6523 - val_accuracy: 0.6431 - val_top_k_categorical_accuracy: 0.8811\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9933 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0333 - accuracy: 0.9933 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6472 - val_accuracy: 0.6454 - val_top_k_categorical_accuracy: 0.8783\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9938 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00058: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 48s 122ms/step - loss: 0.0310 - accuracy: 0.9938 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6221 - val_accuracy: 0.6538 - val_top_k_categorical_accuracy: 0.8799\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9948 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 00059: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 0.0285 - accuracy: 0.9948 - top_k_categorical_accuracy: 0.9999 - val_loss: 1.6386 - val_accuracy: 0.6495 - val_top_k_categorical_accuracy: 0.8778\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9953 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 00060: val_loss did not improve from 1.39592\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 0.0270 - accuracy: 0.9953 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6697 - val_accuracy: 0.6463 - val_top_k_categorical_accuracy: 0.8776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfypPY4e1FhI",
        "outputId": "59bbfccf-4089-423b-9462-30482a26c0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    \n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    \n",
        "    # save plot to file\n",
        "    filename = \"DenseNet201_Pretrained\"\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    \n",
        "\n",
        "summarize_diagnostics(history)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIrtQTco4Cpi"
      },
      "source": [
        "## Final Prediciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZfH79FfXMC",
        "outputId": "9f1c7717-3614-457a-e47b-d26054b73c1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ypred = model.predict(x_test)\n",
        "\n",
        "total = 0\n",
        "accurate = 0\n",
        "accurateindex = []\n",
        "wrongindex = []\n",
        "\n",
        "for i in range(len(ypred)):\n",
        "    if np.argmax(ypred[i]) == np.argmax(y_test[i]):\n",
        "        accurate += 1\n",
        "        accurateindex.append(i)\n",
        "    else:\n",
        "        wrongindex.append(i)\n",
        "        \n",
        "    total += 1\n",
        "    \n",
        "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
        "print('Accuracy:', round(accurate/total*100, 3), '%')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total-test-data; 10000 \taccurately-predicted-data: 6463 \t wrongly-predicted-data:  3537\n",
            "Accuracy: 64.63 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwxfMY5mfXME"
      },
      "source": [
        "### Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4piLJOmfXMF"
      },
      "source": [
        "Ypred = model.predict(x_test)\n",
        "\n",
        "Ypred = np.argmax(Ypred, axis=1)\n",
        "Ytrue = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(Ytrue, Ypred)\n",
        "plt.figure(figsize=(12, 12))\n",
        "ax = sns.heatmap(cm, cmap=\"rocket_r\", fmt=\".01f\",annot_kws={'size':16}, annot=True, square=True, xticklabels=label, yticklabels=label)\n",
        "ax.set_ylabel('Actual', fontsize=20)\n",
        "ax.set_xlabel('Predicted', fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VjSJvdW9fkj",
        "outputId": "d2a08a76-b30c-4864-df28-aec26f6f05f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}