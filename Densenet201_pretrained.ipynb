{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/btran30/cs584/blob/brenda/Densenet201_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY5c1IBb4OVS"
   },
   "source": [
    "# DenseNet 201 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfoamKGa4XSl"
   },
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjZlTdjjfXLr",
    "outputId": "236717a6-9005-4e32-d50d-172006913e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow-version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization,Activation\n",
    "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Tensorflow-version:\", tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8rl-qhF4lP-"
   },
   "source": [
    "## Load Data from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ0MfUxMfXL5",
    "outputId": "1aa067bf-a42a-4928-bf5f-f3dbfc396670"
   },
   "outputs": [],
   "source": [
    "def read_data(cifar_dataset):\n",
    "\n",
    "    if cifar_dataset == 100:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "        # One-hot encoding for 100 classes.\n",
    "        y_train = to_categorical(y_train, 100)\n",
    "        y_test = to_categorical(y_test, 100)\n",
    "    else :\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        y_train = to_categorical(y_train, 10)\n",
    "        y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "    print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "    return (x_train, y_train), (x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjw4aw-b4qEs"
   },
   "source": [
    "## DenseNet 201 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW5ANnlB4xC_"
   },
   "source": [
    "We utilize ImageDataGenerator to augment our input data.  This should help us avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJXdLY1zXqwF",
    "outputId": "f124054a-2c87-452d-99e1-8acc058d6596"
   },
   "outputs": [],
   "source": [
    "def run_model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    input_shape=(32,32,3)\n",
    "    model_d=DenseNet201(weights='imagenet',include_top=False, input_shape=input_shape) \n",
    "\n",
    "    x=model_d.output\n",
    "\n",
    "    x= BatchNormalization()(x)\n",
    "    x= Activation('relu')(x)\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "\n",
    "    preds=Dense(100,activation='softmax')(x) #FC-layer\n",
    "\n",
    "    model=Model(inputs=model_d.input, outputs=preds)\n",
    "\n",
    "    #model.summary()\n",
    "    #tf.keras.utils.plot_model( model , show_shapes=True )\n",
    "\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 5\n",
    "\n",
    "    anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "\n",
    "    datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "    # Fits-the-model\n",
    "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                   steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                   epochs=epochs,\n",
    "                   verbose=1,\n",
    "                   callbacks=[anne],\n",
    "                   validation_data=(x_test, y_test))\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    #filename = \"DenseNet201_Pretrained\"\n",
    "    #plt.savefig(filename + '_plot.png')\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prediction(model, x_test, y_test):\n",
    "    ypred = model.predict(x_test)\n",
    "\n",
    "    total = 0\n",
    "    accurate = 0\n",
    "    accurateindex = []\n",
    "    wrongindex = []\n",
    "\n",
    "    for i in range(len(ypred)):\n",
    "        if np.argmax(ypred[i]) == np.argmax(y_test[i]):\n",
    "            accurate += 1\n",
    "            accurateindex.append(i)\n",
    "        else:\n",
    "            wrongindex.append(i)\n",
    "\n",
    "        total += 1\n",
    "    \n",
    "    print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
    "    print('Accuracy:', round(accurate/total*100, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 100)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 100)\n",
      "Epoch 1/5\n",
      "390/390 [==============================] - 317s 814ms/step - loss: 3.5335 - accuracy: 0.2115 - top_k_categorical_accuracy: 0.4324 - val_loss: 2.6893 - val_accuracy: 0.3571 - val_top_k_categorical_accuracy: 0.6599\n",
      "Epoch 2/5\n",
      "173/390 [============>.................] - ETA: 2:53 - loss: 2.3702 - accuracy: 0.4112 - top_k_categorical_accuracy: 0.7104"
     ]
    }
   ],
   "source": [
    "cifar_dataset = 100\n",
    "(x_train, y_train), (x_test, y_test) = read_data(cifar_dataset)\n",
    "history, model = run_model(x_train, y_train,x_test, y_test)\n",
    "summarize_diagnostics(history)\n",
    "\n",
    "final_prediction(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPZfH79FfXMC",
    "outputId": "48e6c76d-790e-4dfa-a03a-9650777c9cdc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VjSJvdW9fkj",
    "outputId": "d2a08a76-b30c-4864-df28-aec26f6f05f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Densenet201_pretrained.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
