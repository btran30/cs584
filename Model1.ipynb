{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape is : (50000, 32, 32, 3)\n",
      "test_data shape is : (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from six.moves import cPickle as pickle\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Load Pickle File\n",
    "\n",
    "# all_data = pickle.load(open('CIFAR_100_processed.pickle', 'rb'))\n",
    "# train_data = all_data['train_dataset']\n",
    "# test_data = all_data['test_dataset']\n",
    "\n",
    "# train_labels = all_data['train_labels']\n",
    "# test_labels = all_data['test_labels']\n",
    "# label_names = all_data['label_names']\n",
    "\n",
    "# del all_data\n",
    "\n",
    "# # Print Shape Summary\n",
    "\n",
    "# print('train_data shape is : %s' % (train_data.shape,))\n",
    "# print('test_data shape is : %s' % (test_data.shape,))\n",
    "\n",
    "# test_size = test_data.shape[0]\n",
    "# train_size = train_data.shape[0]\n",
    "\n",
    "# # Process Images\n",
    "# train_data = train_data.astype('float32')\n",
    "# test_data = test_data.astype('float32')\n",
    "\n",
    "# train_data = train_data / 255.0\n",
    "# test_data = test_data / 255.0\n",
    "\n",
    "# # OHE Labels\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.cifar100.load_data()\n",
    "\n",
    "# One-hot encoding for 100 classes.\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(): \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "782/782 [==============================] - 99s 127ms/step - loss: 4.7864 - accuracy: 0.0383 - val_loss: 3.9877 - val_accuracy: 0.1081\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 4.1505 - accuracy: 0.0811 - val_loss: 3.8058 - val_accuracy: 0.1375\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 100s 127ms/step - loss: 3.8907 - accuracy: 0.1093 - val_loss: 3.6680 - val_accuracy: 0.1529\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 99s 127ms/step - loss: 3.7133 - accuracy: 0.1333 - val_loss: 3.4980 - val_accuracy: 0.1820\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 99s 126ms/step - loss: 3.5662 - accuracy: 0.1559 - val_loss: 3.3519 - val_accuracy: 0.2074\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 3.4427 - accuracy: 0.1762 - val_loss: 3.3512 - val_accuracy: 0.2044\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 3.3224 - accuracy: 0.1987 - val_loss: 3.2576 - val_accuracy: 0.2284\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 3.2306 - accuracy: 0.2117 - val_loss: 3.1028 - val_accuracy: 0.2532\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 3.1380 - accuracy: 0.2292 - val_loss: 3.0129 - val_accuracy: 0.2681\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 3.0564 - accuracy: 0.2410 - val_loss: 2.9288 - val_accuracy: 0.2847\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 2.9862 - accuracy: 0.2531 - val_loss: 2.8545 - val_accuracy: 0.2922\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.9238 - accuracy: 0.2701 - val_loss: 2.7980 - val_accuracy: 0.3026\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 2.8681 - accuracy: 0.2768 - val_loss: 2.6536 - val_accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 2.8240 - accuracy: 0.2861 - val_loss: 2.6245 - val_accuracy: 0.3358\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 2.7704 - accuracy: 0.2987 - val_loss: 2.5593 - val_accuracy: 0.3522\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.7272 - accuracy: 0.3059 - val_loss: 2.5247 - val_accuracy: 0.3578\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 104s 132ms/step - loss: 2.6960 - accuracy: 0.3120 - val_loss: 2.4745 - val_accuracy: 0.3643\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 2.6534 - accuracy: 0.3208 - val_loss: 2.4555 - val_accuracy: 0.3707\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.6182 - accuracy: 0.3270 - val_loss: 2.3981 - val_accuracy: 0.3837\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 2.5802 - accuracy: 0.3367 - val_loss: 2.3690 - val_accuracy: 0.3867\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 106s 135ms/step - loss: 2.5594 - accuracy: 0.3395 - val_loss: 2.3230 - val_accuracy: 0.3995\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.5299 - accuracy: 0.3486 - val_loss: 2.3085 - val_accuracy: 0.3980\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.4966 - accuracy: 0.3541 - val_loss: 2.2532 - val_accuracy: 0.4134\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 2.4680 - accuracy: 0.3590 - val_loss: 2.2235 - val_accuracy: 0.4166\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.4453 - accuracy: 0.3636 - val_loss: 2.2394 - val_accuracy: 0.4099\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 2.4249 - accuracy: 0.3684 - val_loss: 2.1469 - val_accuracy: 0.4304\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 2.3994 - accuracy: 0.3736 - val_loss: 2.1747 - val_accuracy: 0.4239\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.3829 - accuracy: 0.3769 - val_loss: 2.1644 - val_accuracy: 0.4278\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.3613 - accuracy: 0.3811 - val_loss: 2.1024 - val_accuracy: 0.4405\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.3352 - accuracy: 0.3885 - val_loss: 2.0937 - val_accuracy: 0.4417\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.3212 - accuracy: 0.3915 - val_loss: 2.0613 - val_accuracy: 0.4514\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 2.2968 - accuracy: 0.3976 - val_loss: 2.0487 - val_accuracy: 0.4539\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 2.2743 - accuracy: 0.3991 - val_loss: 2.0754 - val_accuracy: 0.4466\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.2598 - accuracy: 0.4036 - val_loss: 1.9996 - val_accuracy: 0.4645\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 2.2430 - accuracy: 0.4040 - val_loss: 2.0012 - val_accuracy: 0.4632\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.2303 - accuracy: 0.4078 - val_loss: 1.9962 - val_accuracy: 0.4619\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.2052 - accuracy: 0.4135 - val_loss: 1.9793 - val_accuracy: 0.4685\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.1903 - accuracy: 0.4164 - val_loss: 1.9336 - val_accuracy: 0.4788\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.1813 - accuracy: 0.4206 - val_loss: 1.9728 - val_accuracy: 0.4703\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.1662 - accuracy: 0.4213 - val_loss: 1.9309 - val_accuracy: 0.4780\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.1508 - accuracy: 0.4272 - val_loss: 1.9239 - val_accuracy: 0.4779\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 2.1364 - accuracy: 0.4288 - val_loss: 1.9216 - val_accuracy: 0.4813\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 2.1256 - accuracy: 0.4301 - val_loss: 1.9401 - val_accuracy: 0.4754\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 2.1056 - accuracy: 0.4363 - val_loss: 1.8818 - val_accuracy: 0.4883\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.0899 - accuracy: 0.4400 - val_loss: 1.8849 - val_accuracy: 0.4836\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 2.0764 - accuracy: 0.4428 - val_loss: 1.8899 - val_accuracy: 0.4865\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 2.0646 - accuracy: 0.4466 - val_loss: 1.8587 - val_accuracy: 0.4969\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.0476 - accuracy: 0.4481 - val_loss: 1.8386 - val_accuracy: 0.4946\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 2.0380 - accuracy: 0.4514 - val_loss: 1.8422 - val_accuracy: 0.4948\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 2.0170 - accuracy: 0.4570 - val_loss: 1.8234 - val_accuracy: 0.5012\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 2.0076 - accuracy: 0.4596 - val_loss: 1.7861 - val_accuracy: 0.5101\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 2.0003 - accuracy: 0.4580 - val_loss: 1.8140 - val_accuracy: 0.5049\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 1.9911 - accuracy: 0.4631 - val_loss: 1.8061 - val_accuracy: 0.5065\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.9751 - accuracy: 0.4660 - val_loss: 1.7955 - val_accuracy: 0.5100\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 1.9566 - accuracy: 0.4690 - val_loss: 1.7834 - val_accuracy: 0.5095\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 1.9512 - accuracy: 0.4725 - val_loss: 1.7713 - val_accuracy: 0.5166\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 1.9426 - accuracy: 0.4720 - val_loss: 1.7893 - val_accuracy: 0.5067\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 1.9237 - accuracy: 0.4783 - val_loss: 1.7660 - val_accuracy: 0.5119\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 1.9185 - accuracy: 0.4776 - val_loss: 1.7492 - val_accuracy: 0.5170\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.9095 - accuracy: 0.4822 - val_loss: 1.7459 - val_accuracy: 0.5188\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.8925 - accuracy: 0.4826 - val_loss: 1.7439 - val_accuracy: 0.5238\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.8898 - accuracy: 0.4847 - val_loss: 1.7979 - val_accuracy: 0.5090\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 1.8830 - accuracy: 0.4866 - val_loss: 1.7553 - val_accuracy: 0.5167\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.8657 - accuracy: 0.4899 - val_loss: 1.7237 - val_accuracy: 0.5259\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 104s 132ms/step - loss: 1.8607 - accuracy: 0.4923 - val_loss: 1.7308 - val_accuracy: 0.5237\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 1.8480 - accuracy: 0.4936 - val_loss: 1.6968 - val_accuracy: 0.5273\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 108s 138ms/step - loss: 1.8426 - accuracy: 0.4945 - val_loss: 1.6946 - val_accuracy: 0.5292\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 1.8276 - accuracy: 0.4962 - val_loss: 1.6843 - val_accuracy: 0.5326\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.8138 - accuracy: 0.5004 - val_loss: 1.6736 - val_accuracy: 0.5319\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 1.8113 - accuracy: 0.5012 - val_loss: 1.6707 - val_accuracy: 0.5393\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 1.8003 - accuracy: 0.5079 - val_loss: 1.6864 - val_accuracy: 0.5348\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 1.7853 - accuracy: 0.5067 - val_loss: 1.6976 - val_accuracy: 0.5337\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.7818 - accuracy: 0.5067 - val_loss: 1.6729 - val_accuracy: 0.5347\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 104s 132ms/step - loss: 1.7794 - accuracy: 0.5078 - val_loss: 1.6824 - val_accuracy: 0.5324\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 1.7745 - accuracy: 0.5094 - val_loss: 1.6567 - val_accuracy: 0.5424\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 1.7556 - accuracy: 0.5144 - val_loss: 1.6406 - val_accuracy: 0.5458\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 1.7386 - accuracy: 0.5157 - val_loss: 1.6418 - val_accuracy: 0.5463\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 1.7371 - accuracy: 0.5180 - val_loss: 1.6340 - val_accuracy: 0.5458\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.7293 - accuracy: 0.5203 - val_loss: 1.6323 - val_accuracy: 0.5440\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.7235 - accuracy: 0.5215 - val_loss: 1.6114 - val_accuracy: 0.5532\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 106s 136ms/step - loss: 1.7164 - accuracy: 0.5243 - val_loss: 1.6498 - val_accuracy: 0.5411\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 107s 136ms/step - loss: 1.7129 - accuracy: 0.5245 - val_loss: 1.6323 - val_accuracy: 0.5455\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.6932 - accuracy: 0.5286 - val_loss: 1.6359 - val_accuracy: 0.5454\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 105s 135ms/step - loss: 1.6898 - accuracy: 0.5313 - val_loss: 1.6218 - val_accuracy: 0.5492\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 1.6877 - accuracy: 0.5271 - val_loss: 1.6334 - val_accuracy: 0.5422\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 1.6727 - accuracy: 0.5322 - val_loss: 1.5988 - val_accuracy: 0.5498\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 1.6701 - accuracy: 0.5355 - val_loss: 1.6200 - val_accuracy: 0.5464\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 1.6585 - accuracy: 0.5405 - val_loss: 1.6149 - val_accuracy: 0.5478\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 1.6589 - accuracy: 0.5377 - val_loss: 1.5763 - val_accuracy: 0.5573\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.6436 - accuracy: 0.5402 - val_loss: 1.6269 - val_accuracy: 0.5418\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 1.6425 - accuracy: 0.5384 - val_loss: 1.6010 - val_accuracy: 0.5525\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 1.6296 - accuracy: 0.5421 - val_loss: 1.5813 - val_accuracy: 0.5583\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 1.6227 - accuracy: 0.5448 - val_loss: 1.6136 - val_accuracy: 0.5522\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 1.6138 - accuracy: 0.5480 - val_loss: 1.5816 - val_accuracy: 0.5583\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 105s 135ms/step - loss: 1.6194 - accuracy: 0.5471 - val_loss: 1.5602 - val_accuracy: 0.5632\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 1.6063 - accuracy: 0.5479 - val_loss: 1.5607 - val_accuracy: 0.5609\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 106s 135ms/step - loss: 1.6009 - accuracy: 0.5490 - val_loss: 1.5785 - val_accuracy: 0.5569\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 106s 135ms/step - loss: 1.5871 - accuracy: 0.5546 - val_loss: 1.5554 - val_accuracy: 0.5645\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 1.5872 - accuracy: 0.5529 - val_loss: 1.5659 - val_accuracy: 0.5591\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 104s 134ms/step - loss: 1.5781 - accuracy: 0.5540 - val_loss: 1.5647 - val_accuracy: 0.5647\n",
      "> 56.470\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = define_model()\n",
    "\n",
    "# fit model\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(test_data, test_labels), verbose=1)\n",
    "\n",
    "# evaluate model\n",
    "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# learning curves\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
