{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization,Activation\n",
    "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Tensorflow-version:\", tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.cifar100.load_data()\n",
    "\n",
    "# One-hot encoding for 100 classes.\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet 201 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We utilize ImageDataGenerator to augment our input data. This should help us avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(32,32,3)\n",
    "model_d=DenseNet201(weights='imagenet',include_top=False, input_shape=input_shape) \n",
    "\n",
    "x=model_d.output\n",
    "\n",
    "x= BatchNormalization()(x)\n",
    "x= Activation('relu')(x)\n",
    "x= GlobalAveragePooling2D()(x)\n",
    "\n",
    "preds=Dense(100,activation='softmax')(x) #FC-layer\n",
    "\n",
    "model=Model(inputs=model_d.input, outputs=preds)\n",
    "\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model( model , show_shapes=True )\n",
    "\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "\n",
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "# Fits-the-model\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "               steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "               epochs=epochs,\n",
    "               verbose=1,\n",
    "               callbacks=[anne, checkpoint],\n",
    "               validation_data=(x_test, y_test))\n",
    "\n",
    "#model.save(\"m_densenet201.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    filename = \"DenseNet201_Pretrained\"\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(x_test)\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "accurateindex = []\n",
    "wrongindex = []\n",
    "\n",
    "for i in range(len(ypred)):\n",
    "    if np.argmax(ypred[i]) == np.argmax(y_test[i]):\n",
    "        accurate += 1\n",
    "        accurateindex.append(i)\n",
    "    else:\n",
    "        wrongindex.append(i)\n",
    "        \n",
    "    total += 1\n",
    "    \n",
    "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
    "print('Accuracy:', round(accurate/total*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = model.predict(x_test)\n",
    "\n",
    "Ypred = np.argmax(Ypred, axis=1)\n",
    "Ytrue = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(Ytrue, Ypred)\n",
    "plt.figure(figsize=(12, 12))\n",
    "ax = sns.heatmap(cm, cmap=\"rocket_r\", fmt=\".01f\",annot_kws={'size':16}, annot=True, square=True, xticklabels=label, yticklabels=label)\n",
    "ax.set_ylabel('Actual', fontsize=20)\n",
    "ax.set_xlabel('Predicted', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
